{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e365a256-fb81-4a83-8ac2-76b42e7b6971",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**CONFIG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29f6355-95b9-415a-a2ba-1ddf3da631d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load metadata\n",
    "config_path = \"/Workspace/Repos/parth.b2109@gmail.com/modastyle-dataeng/configs/tables.json\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "table_conf = meta[\"store_sales\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65b4fe8f-8b17-4196-be3b-a6848666f41c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.ignoreCorruptFiles\", \"true\")\n",
    "spark.conf.set(\"spark.sql.files.ignoreMissingFiles\", \"true\")\n",
    "spark.conf.set(\"spark.sql.badRecordsPath\", f\"/mnt/modastyle/bad_records/store_sales/{ingest_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b9d4c12-8159-4b7e-80e7-75cf47beaad3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ingest_raw_and_bronze_store_sales.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name, current_timestamp, lit\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "# Either pass this as widget or edit here for quick run\n",
    "dbutils.widgets.text(\"ingest_date\", datetime.date.today().strftime(\"%Y-%m-%d\"))\n",
    "ingest_date = dbutils.widgets.get(\"ingest_date\")\n",
    "\n",
    "# Paths\n",
    "source_base   = table_conf[\"source_path\"]\n",
    "raw_base      = table_conf[\"raw_path\"]\n",
    "bronze_base   = table_conf[\"bronze_path\"]\n",
    "bad_base      = table_conf[\"bad_records_path\"]\n",
    "pk_cols       = table_conf[\"primary_key\"]\n",
    "partition_col = table_conf[\"partition_column\"]\n",
    "\n",
    "\n",
    "# Derived\n",
    "raw_target = f\"{raw_base}/dt={ingest_date}\"\n",
    "bronze_target = f\"{bronze_base}/dt={ingest_date}\"\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "print(f\"Run: {run_id} | ingest_date: {ingest_date}\")\n",
    "print(\"Source:\", source_base)\n",
    "print(\"Raw target:\", raw_target)\n",
    "print(\"Bronze target:\", bronze_target)\n",
    "\n",
    "\n",
    "bad_records_path = f\"/mnt/modastyle/bad_records/store_sales/{ingest_date}\"\n",
    "spark.conf.set(\"spark.sql.badRecordsPath\", bad_records_path)\n",
    "\n",
    "# --- READ SOURCE (flexible: folder or files) ---\n",
    "try:\n",
    "    df_src = (spark.read\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"false\")     # <-- read everything as STRING\n",
    "            .option(\"mode\", \"PERMISSIVE\")       # <-- allow bad rows\n",
    "            .csv(source_base))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"No files found in source. Exiting.\")\n",
    "    raise\n",
    "\n",
    "rows_in = df_src.count()\n",
    "print(\"Rows in source:\", rows_in)\n",
    "\n",
    "bad_count = 0\n",
    "try:\n",
    "    bad_count = len(dbutils.fs.ls(bad_records_path))\n",
    "    print(f\"Bad record files: {bad_count}\")\n",
    "except:\n",
    "    print(\"No bad records folder found.\")\n",
    "\n",
    "# --- WRITE RAW (just copy CSV rows as-is into raw partition) ---\n",
    "# write as CSV to raw partition (preserve original CSV structure)\n",
    "(df_src.write\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(raw_target))\n",
    "\n",
    "print(\"Raw write complete.\")\n",
    "\n",
    "# --- BASIC CLEANING FOR BRONZE ---\n",
    "# add metadata columns\n",
    "df_bronze = (df_src\n",
    "             .withColumn(\"source_file\", input_file_name())\n",
    "             .withColumn(\"ingest_ts\", current_timestamp())\n",
    "             .withColumn(\"ingest_date\", lit(ingest_date))\n",
    "             .withColumn(\"run_id\", lit(run_id))\n",
    "             .withColumn(\"layer\", lit(\"bronze\")))\n",
    "\n",
    "# convert to Delta (create folder if not exists)\n",
    "(df_bronze.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(bronze_target))\n",
    "\n",
    "rows_written = spark.read.format(\"delta\").load(bronze_target).count()\n",
    "print(\"Rows written to bronze:\", rows_written)\n",
    "\n",
    "# --- SIMPLE AUDIT LOG (append to delta audit table) ---\n",
    "audit = spark.createDataFrame([(\n",
    "    run_id, \"store_sales\", source_base, raw_target, bronze_target,\n",
    "    rows_in, rows_written, bad_count, datetime.datetime.now().isoformat()\n",
    ")], schema=[\"run_id\",\"table\",\"source_path\",\"raw_path\",\"bronze_path\",\"rows_in\",\"rows_written\",\"bad_count\",\"audit_ts\"])\n",
    "\n",
    "audit_table_path = \"/mnt/modastyle/_audit/ingest_runs\"\n",
    "# create folder if not exists\n",
    "\n",
    "\n",
    "(audit.write\n",
    "     .format(\"delta\")\n",
    "     .mode(\"append\")\n",
    "     .save(audit_table_path))\n",
    "\n",
    "print(\"Audit appended to:\", audit_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d6d2666-da7b-4396-a1b8-2021c7ce4714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\"/mnt/modastyle/bronze/store_sales\", recurse=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_raw_and_bronze_store_sales.py",
   "widgets": {
    "ingest_date": {
     "currentValue": "2025-11-17",
     "nuid": "d7034580-5778-444a-a900-c3507adb5ec1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-11-17",
      "label": null,
      "name": "ingest_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-11-17",
      "label": null,
      "name": "ingest_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
